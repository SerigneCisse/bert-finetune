{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import utils\n",
    "import bert_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "MAX_SEQ_LEN = 512\n",
    "BERT_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training Set\n",
    "\n",
    "The `load_ag_news_dataset` function performs the following:\n",
    "\n",
    "1. Fetch dataset from the Internet\n",
    "2. Load into memory\n",
    "3. Perform basic preprocessing and shuffling\n",
    "\n",
    "The test set can be loaded in the same way by setting the argument `test=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training set from: /home/jovyan/.keras/datasets/ag_news\n",
      "Examples: 120000 Classes: 4\n"
     ]
    }
   ],
   "source": [
    "train_text, train_label, num_classes = utils.load_ag_news_dataset(max_seq_len=MAX_SEQ_LEN,\n",
    "                                                                  test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demo purposes in this notebook, we will only take the first 4 training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, train_label = train_text[:4], train_label[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 They really do drive for show Theirs is a golfing world without bunkers and hazards, sloping greens and Sunday pins. Only one thing matters to the professional long driver, and it's measured in yards, not strokes. \n",
      "\n",
      "3 Google Plans Desktop Search Tool for Apple PCs LOS ANGELES (Reuters) - Google Inc. &lt;A HREF=\"http://www.reuters.co.uk/financeQuoteLookup.jhtml?ticker=GOOG.O qtype=sym infotype=info qcat=news\"&gt;GOOG.O&lt;/A&gt; plans to release a version of its desktop search tool for computers running on the Mac operating system from Apple Computer Inc. &lt;A HREF=\"http://www.reuters.co.uk/financeQuoteLookup.jhtml?ticker=AAPL.O qtype=sym infotype=info qcat=news\"&gt;AAPL.O&lt;/A&gt;, Google chief executive Eric Schmidt said on Friday. \n",
      "\n",
      "3 Sony #39;s Vaio X: Like TiVo on Steroids CHIBA, JAPAN -- Sony will begin selling in Japan in November a combination personal computer and video server that can record up to seven channels of television simultaneously, it said at the Ceatec 2004 exhibition here. \n",
      "\n",
      "2 Earnings at BAT are full of puff BRITISH American Tobacco is continuing to make good profits on the strength of its four main cigarette brands: Lucky Strike, Kent, Dunhill and Pall Mall cigarettes. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(train_text):\n",
    "    print(train_label[i], text[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = bert_utils.create_tokenizer_from_hub_module(BERT_PATH,\n",
    "                                                        tf.Session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the text and convert into `InputExample` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = bert_utils.convert_text_to_examples(train_text, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<bert_utils.InputExample object at 0x7f338c733710>, <bert_utils.InputExample object at 0x7f338c733748>, <bert_utils.InputExample object at 0x7f338c733780>, <bert_utils.InputExample object at 0x7f338c7337b8>]\n"
     ]
    }
   ],
   "source": [
    "print(train_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Data\n",
    "\n",
    "Convert `InputExample` objects back into numpy arrays to fit into the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting examples to features: 100%|██████████| 4/4 [00:00<00:00, 759.84it/s]\n"
     ]
    }
   ],
   "source": [
    "feat = bert_utils.convert_examples_to_features(tokenizer,\n",
    "                                               train_examples,\n",
    "                                               max_seq_length=MAX_SEQ_LEN,\n",
    "                                               verbose=1)\n",
    "\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels) = feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Tokens\n",
    "\n",
    "Each token represents a unique WordPiece. Each array represents a training example with up to 512 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2027,  2428, ...,     0,     0,     0],\n",
       "       [  101,  8224,  3488, ...,     0,     0,     0],\n",
       "       [  101,  8412,  1001, ...,     0,     0,     0],\n",
       "       [  101, 16565,  2012, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segment_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
